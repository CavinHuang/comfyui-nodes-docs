# Documentation
- Class name: ColorAdapter
- Category: ðŸ˜ºdzNodes/LayerColor
- Output node: False
- Repo Ref: https://github.com/chflame163/ComfyUI_LayerStyle

è‡ªåŠ¨è°ƒæ•´å›¾ç‰‡è‰²è°ƒï¼Œä½¿ä¹‹ä¸Žå‚è€ƒå›¾ç‰‡ç›¸ä¼¼ã€‚

# Input types
## Required

- image
    - è¾“å…¥çš„å›¾ç‰‡ã€‚
    - Comfy dtype: IMAGE
    - Python dtype: torch.Tensor

- color_ref_image
    - å‚è€ƒå›¾ç‰‡ã€‚
    - Comfy dtype: IMAGE
    - Python dtype: torch.Tensor

- opacity
    -  å›¾åƒè°ƒæ•´è‰²è°ƒä¹‹åŽçš„ä¸é€æ˜Žåº¦ã€‚
    - Comfy dtype: INT
    - Python dtype: int
    - å–å€¼èŒƒå›´: 0-100

# Output types

- image
    - è¾“å‡ºçš„å›¾ç‰‡ã€‚
    - Comfy dtype: IMAGE
    - Python dtype: torch.Tensor

# Usage tips
- Infra type: GPU

# Source code
```
class ColorAdapter:

    def __init__(self):
        pass

    @classmethod
    def INPUT_TYPES(self):

        return {
            "required": {
                "image": ("IMAGE", ),  #
                "color_ref_image": ("IMAGE", ),  #
                "opacity": ("INT", {"default": 75, "min": 0, "max": 100, "step": 1}),  # é€æ˜Žåº¦
            },
            "optional": {
            }
        }

    RETURN_TYPES = ("IMAGE",)
    RETURN_NAMES = ("image",)
    FUNCTION = 'color_adapter'
    CATEGORY = 'ðŸ˜ºdzNodes/LayerColor'

    def color_adapter(self, image, color_ref_image, opacity):
        ret_images = []

        l_images = []
        r_images = []
        for l in image:
            l_images.append(torch.unsqueeze(l, 0))
        for r in color_ref_image:
            r_images.append(torch.unsqueeze(r, 0))
        for i in range(len(l_images)):
            _image = l_images[i]
            _ref = r_images[i] if len(ret_images) > i else r_images[-1]

            __image = tensor2pil(_image)
            _canvas = __image.convert('RGB')
            ret_image = color_adapter(_canvas, tensor2pil(_ref).convert('RGB'))
            ret_image = chop_image(_canvas, ret_image, blend_mode='normal', opacity=opacity)
            if __image.mode == 'RGBA':
                ret_image = RGB2RGBA(ret_image, __image.split()[-1])
            ret_images.append(pil2tensor(ret_image))

        log(f"{NODE_NAME} Processed {len(ret_images)} image(s).", message_type='finish')
        return (torch.cat(ret_images, dim=0),)
```