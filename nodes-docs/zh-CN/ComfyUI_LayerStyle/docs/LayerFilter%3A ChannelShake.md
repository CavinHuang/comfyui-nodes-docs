# Documentation
- Class name: ChannelShake
- Category: ğŸ˜ºdzNodes/LayerFilter
- Output node: False
- Repo Ref: https://github.com/chflame163/ComfyUI_LayerStyle

é€šé“é”™ä½ã€‚ç±»ä¼¼æŠ–éŸ³logoçš„æ•ˆæœã€‚

# Input types
## Required

- image
    - è¾“å…¥çš„å›¾ç‰‡ã€‚
    - Comfy dtype: IMAGE
    - Python dtype: torch.Tensor

- distance
    - é€šé“é”™ä½çš„è·ç¦»ã€‚
    - Comfy dtype: INT
    - Python dtype: int
    - å–å€¼èŒƒå›´: 1-999

- angle
    - é€šé“é”™ä½çš„è§’åº¦ã€‚
    - Comfy dtype: FLOAT
    - Python dtype: float
    - å–å€¼èŒƒå›´: -360-360

- mode
    - é€šé“é”™ä½çš„æ¨¡å¼ã€‚
    - Comfy dtype: ENUM
    - Python dtype: str
    - å¯é€‰å€¼: RGB, RBG, BGR, BRG, GBR, GRB

# Output types

- image
    - è¾“å‡ºçš„å›¾ç‰‡ã€‚
    - Comfy dtype: IMAGE
    - Python dtype: torch.Tensor

# Usage tips
- Infra type: GPU

# Source code
```
class ChannelShake:

    def __init__(self):
        pass

    @classmethod
    def INPUT_TYPES(self):
        channel_mode = ['RGB', 'RBG', 'BGR', 'BRG', 'GBR', 'GRB']
        return {
            "required": {
                "image": ("IMAGE", ),  #
                "distance": ("INT", {"default": 20, "min": 1, "max": 999, "step": 1}),  # è·ç¦»
                "angle": ("FLOAT", {"default": 40, "min": -360, "max": 360, "step": 0.1}),  # è§’åº¦
                "mode": (channel_mode,),  # æ¨¡å¼
            },
            "optional": {
            }
        }

    RETURN_TYPES = ("IMAGE",)
    RETURN_NAMES = ("image",)
    FUNCTION = 'channel_shake'
    CATEGORY = 'ğŸ˜ºdzNodes/LayerFilter'

    def channel_shake(self, image, distance, angle, mode, ):

        ret_images = []

        for i in image:
            i = torch.unsqueeze(i, 0)
            _canvas = tensor2pil(i).convert('RGB')
            R, G, B = _canvas.split()
            x = int(math.cos(angle) * distance)
            y = int(math.sin(angle) * distance)
            if mode.startswith('R'):
                R = shift_image(R.convert('RGB'), -x, -y).convert('L')
            if mode.startswith('G'):
                G = shift_image(G.convert('RGB'), -x, -y).convert('L')
            if mode.startswith('B'):
                B = shift_image(B.convert('RGB'), -x, -y).convert('L')
            if mode.endswith('R'):
                R = shift_image(R.convert('RGB'), x, y).convert('L')
            if mode.endswith('G'):
                G = shift_image(G.convert('RGB'), x, y).convert('L')
            if mode.endswith('B'):
                B = shift_image(B.convert('RGB'), x, y).convert('L')

            ret_image = Image.merge('RGB', [R, G, B])
            ret_images.append(pil2tensor(ret_image))

        log(f"{NODE_NAME} Processed {len(ret_images)} image(s).", message_type='finish')
        return (torch.cat(ret_images, dim=0),)
```