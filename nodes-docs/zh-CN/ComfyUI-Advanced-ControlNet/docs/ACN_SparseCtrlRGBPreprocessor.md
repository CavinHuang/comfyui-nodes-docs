# Documentation
- Class name: RgbSparseCtrlPreprocessor
- Category: Adv-ControlNet ğŸ›‚ğŸ…ğŸ…’ğŸ…/SparseCtrl/preprocess
- Output node: False
- Repo Ref: https://github.com/Kosinkadink/ComfyUI-Advanced-ControlNet.git

RgbSparseCtrlPreprocessorèŠ‚ç‚¹æ—¨åœ¨ä¸ºæ¶‰åŠç¨€ç–æ§åˆ¶æœºåˆ¶çš„é«˜çº§æ§åˆ¶ç½‘ç»œå¤„ç†å‡†å¤‡å›¾åƒæ•°æ®ã€‚å®ƒå°†è¾“å…¥å›¾åƒæ”¾å¤§ä»¥åŒ¹é…æ½œåœ¨å¤§å°ï¼Œå°†å›¾åƒç¼–ç ä¸ºæ½œåœ¨ç©ºé—´è¡¨ç¤ºï¼Œå¹¶ä»¥ç‰¹å®šäºä¸‹æ¸¸æ§åˆ¶ç½‘ç»œåº”ç”¨çš„é¢„å¤„ç†æ ¼å¼åŒ…è£…ç¼–ç æ•°æ®ã€‚

# Input types
## Required
- image
    - å›¾åƒå‚æ•°å¯¹äºé¢„å¤„ç†é˜¶æ®µè‡³å…³é‡è¦ï¼Œå› ä¸ºå®ƒä»£è¡¨äº†å°†è¢«æ”¾å¤§å’Œç¼–ç çš„åŸå§‹è¾“å…¥ã€‚å®ƒæ˜¯å½±å“èŠ‚ç‚¹è¾“å‡ºå’Œæ§åˆ¶ç½‘ç»œä¸­åç»­å¤„ç†çš„åŸºæœ¬å…ƒç´ ã€‚
    - Comfy dtype: IMAGE
    - Python dtype: torch.Tensor
- vae
    - vaeå‚æ•°æŒ‡å®šäº†å˜åˆ†è‡ªç¼–ç å™¨ï¼ˆVAEï¼‰æ¨¡å‹ï¼Œè¯¥æ¨¡å‹å°†ç”¨äºå°†å›¾åƒç¼–ç ä¸ºæ½œåœ¨è¡¨ç¤ºã€‚è¿™ä¸ªæ¨¡å‹å¯¹äºèŠ‚ç‚¹å°†è¾“å…¥å›¾åƒè½¬æ¢ä¸ºé€‚åˆé«˜çº§æ§åˆ¶ç½‘ç»œæ“ä½œçš„æ ¼å¼è‡³å…³é‡è¦ã€‚
    - Comfy dtype: VAE
    - Python dtype: comfy.sd.VAE
- latent_size
    - latent_sizeå‚æ•°å®šä¹‰äº†å›¾åƒå°†è¢«ç¼–ç çš„æ½œåœ¨ç©ºé—´çš„ç»´åº¦ã€‚å®ƒæ˜¯èŠ‚ç‚¹è¾“å‡ºè´¨é‡çš„å…³é”®å†³å®šå› ç´ ï¼Œä»¥åŠç¼–ç æ•°æ®åœ¨æ§åˆ¶ç½‘ç»œæ¡†æ¶å†…çš„åç»­é€‚ç”¨æ€§ã€‚
    - Comfy dtype: LATENT
    - Python dtype: Dict[str, torch.Tensor]

# Output types
- proc_IMAGE
    - proc_IMAGEè¾“å‡ºæ˜¯è¾“å…¥å›¾åƒçš„é¢„å¤„ç†ç‰ˆæœ¬ï¼Œç¼–ç ä¸ºæ½œåœ¨ç©ºé—´è¡¨ç¤ºã€‚æ­¤è¾“å‡ºä¸“é—¨è®¾è®¡ä¸ºä¸é«˜çº§æ§åˆ¶ç½‘ç»œèŠ‚ç‚¹å…¼å®¹ï¼Œä¸æ‰“ç®—ç”¨äºå…¶ä»–ç±»å‹çš„å›¾åƒè¾“å…¥ã€‚
    - Comfy dtype: IMAGE
    - Python dtype: PreprocSparseRGBWrapper

# Usage tips
- Infra type: GPU

# Source code
```
class RgbSparseCtrlPreprocessor:

    @classmethod
    def INPUT_TYPES(s):
        return {'required': {'image': ('IMAGE',), 'vae': ('VAE',), 'latent_size': ('LATENT',)}}
    RETURN_TYPES = ('IMAGE',)
    RETURN_NAMES = ('proc_IMAGE',)
    FUNCTION = 'preprocess_images'
    CATEGORY = 'Adv-ControlNet ğŸ›‚ğŸ…ğŸ…’ğŸ…/SparseCtrl/preprocess'

    def preprocess_images(self, vae: VAE, image: Tensor, latent_size: Tensor):
        image = image.movedim(-1, 1)
        image = comfy.utils.common_upscale(image, latent_size['samples'].shape[3] * 8, latent_size['samples'].shape[2] * 8, 'nearest-exact', 'center')
        image = image.movedim(1, -1)
        try:
            image = vae.vae_encode_crop_pixels(image)
        except Exception:
            image = VAEEncode.vae_encode_crop_pixels(image)
        encoded = vae.encode(image[:, :, :, :3])
        return (PreprocSparseRGBWrapper(condhint=encoded),)
```