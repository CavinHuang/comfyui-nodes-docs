# Documentation
- Class name: ReferencePreprocessorNode
- Category: Adv-ControlNet ğŸ›‚ğŸ…ğŸ…’ğŸ…/Reference/preprocess
- Output node: False
- Repo Ref: https://github.com/Kosinkadink/ComfyUI-Advanced-ControlNet.git

ReferencePreprocessorNode æ—¨åœ¨ä½¿ç”¨å˜åˆ†è‡ªç¼–ç å™¨ï¼ˆVAEï¼‰å°†è¾“å…¥å›¾åƒè½¬æ¢ä¸ºæ½œåœ¨ç©ºé—´è¡¨ç¤ºã€‚å®ƒåœ¨ä¸ºé«˜çº§æ§åˆ¶ç½‘ç»œæ“ä½œå‡†å¤‡å›¾åƒæ–¹é¢å‘æŒ¥ç€å…³é”®ä½œç”¨ï¼Œé€šè¿‡å°†è§†è§‰å†…å®¹ç¼–ç ä¸ºå¯ä»¥ç”±ä¸‹æ¸¸èŠ‚ç‚¹è¿›ä¸€æ­¥å¤„ç†çš„æ ¼å¼ã€‚

# Input types
## Required
- image
    - å›¾åƒå‚æ•°å¯¹äºèŠ‚ç‚¹çš„æ“ä½œè‡³å…³é‡è¦ï¼Œå› ä¸ºå®ƒæ˜¯éœ€è¦è¢«é¢„å¤„ç†çš„åŸå§‹è§†è§‰è¾“å…¥ã€‚å®ƒæ˜¯èŠ‚ç‚¹å°†è½¬æ¢ä¸ºæ½œåœ¨è¡¨ç¤ºçš„ä¸»è¦æ•°æ®ã€‚
    - Comfy dtype: IMAGE
    - Python dtype: torch.Tensor
- vae
    - VAE å‚æ•°æŒ‡å®šäº†èŠ‚ç‚¹å°†ç”¨äºå°†å›¾åƒç¼–ç ä¸ºæ½œåœ¨ç©ºé—´çš„å˜åˆ†è‡ªç¼–ç å™¨æ¨¡å‹ã€‚è¿™ä¸ªæ¨¡å‹æ˜¯èŠ‚ç‚¹åŠŸèƒ½çš„æ ¸å¿ƒï¼Œå› ä¸ºå®ƒå®šä¹‰äº†å›¾åƒå¦‚ä½•è¢«è½¬æ¢ã€‚
    - Comfy dtype: VAE
    - Python dtype: comfy.sd.VAE
- latent_size
    - latent_size å‚æ•°å®šä¹‰äº†å›¾åƒå°†è¢«ç¼–ç çš„æ½œåœ¨ç©ºé—´çš„ç»´åº¦ã€‚å®ƒæ˜¯ä¸€ä¸ªå…³é”®ç»„ä»¶ï¼Œå› ä¸ºå®ƒå†³å®šäº†ç¼–ç è¡¨ç¤ºçš„è§„æ¨¡å’Œç»“æ„ã€‚
    - Comfy dtype: LATENT
    - Python dtype: Dict[str, Any]

# Output types
- proc_IMAGE
    - proc_IMAGE è¾“å‡ºæ˜¯ä»¥æ½œåœ¨è¡¨ç¤ºå½¢å¼å¤„ç†åçš„å›¾åƒã€‚å®ƒå¾ˆé‡è¦ï¼Œå› ä¸ºå®ƒä½œä¸ºæ§åˆ¶ç½‘ç»œä¸­åç»­èŠ‚ç‚¹çš„è¾“å…¥ï¼Œä½¿å¾—å¯ä»¥è¿›è¡Œæ›´é«˜çº§çš„å¤„ç†ã€‚
    - Comfy dtype: IMAGE
    - Python dtype: comfy.utils.ReferencePreprocWrapper

# Usage tips
- Infra type: GPU

# Source code
```
class ReferencePreprocessorNode:

    @classmethod
    def INPUT_TYPES(s):
        return {'required': {'image': ('IMAGE',), 'vae': ('VAE',), 'latent_size': ('LATENT',)}}
    RETURN_TYPES = ('IMAGE',)
    RETURN_NAMES = ('proc_IMAGE',)
    FUNCTION = 'preprocess_images'
    CATEGORY = 'Adv-ControlNet ğŸ›‚ğŸ…ğŸ…’ğŸ…/Reference/preprocess'

    def preprocess_images(self, vae: VAE, image: Tensor, latent_size: Tensor):
        image = image.movedim(-1, 1)
        image = comfy.utils.common_upscale(image, latent_size['samples'].shape[3] * 8, latent_size['samples'].shape[2] * 8, 'nearest-exact', 'center')
        image = image.movedim(1, -1)
        try:
            image = vae.vae_encode_crop_pixels(image)
        except Exception:
            image = VAEEncode.vae_encode_crop_pixels(image)
        encoded = vae.encode(image[:, :, :, :3])
        return (ReferencePreprocWrapper(condhint=encoded),)
```