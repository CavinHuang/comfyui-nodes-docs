---
tags:
- Sampling
---

# KSampler SDXL (Eff.)
## Documentation
- Class name: `KSampler SDXL (Eff.)`
- Category: `Efficiency Nodes/Sampling`
- Output node: `True`

The KSampler SDXL (Eff.) node is designed for efficient sampling in the context of generative models, specifically tailored for handling Stable Diffusion XL models. It extends the capabilities of regular and advanced KSampler nodes by incorporating specialized sampling strategies that accommodate the unique requirements of SDXL models, such as handling larger model sizes and optimizing for performance without compromising on the quality of generated samples.
## Input types
### Required
- **`sdxl_tuple`**
    - Represents the model parameters and configurations specific to Stable Diffusion XL, serving as the primary input for the sampling process. It is crucial for defining the behavior and performance of the sampling operation.
    - Comfy dtype: `SDXL_TUPLE`
    - Python dtype: `tuple`
- **`noise_seed`**
    - A seed value used to initialize the noise generation process, ensuring reproducibility and consistency in the samples generated by the model.
    - Comfy dtype: `INT`
    - Python dtype: `int`
- **`steps`**
    - Specifies the number of steps to be executed in the sampling process, directly influencing the detail and quality of the generated images.
    - Comfy dtype: `INT`
    - Python dtype: `int`
- **`cfg`**
    - The conditioning factor that adjusts the influence of the textual prompt on the generated image, allowing for finer control over the sampling process.
    - Comfy dtype: `FLOAT`
    - Python dtype: `float`
- **`sampler_name`**
    - Identifies the specific sampler configuration to be used, enabling customization and optimization of the sampling process for different use cases.
    - Comfy dtype: `COMBO[STRING]`
    - Python dtype: `str`
- **`scheduler`**
    - Determines the scheduling strategy for the sampling process, impacting the progression and quality of image generation.
    - Comfy dtype: `COMBO[STRING]`
    - Python dtype: `str`
- **`latent_image`**
    - The initial latent image input that serves as a starting point for the sampling process, which can be modified or refined through subsequent steps.
    - Comfy dtype: `LATENT`
    - Python dtype: `torch.Tensor`
- **`start_at_step`**
    - Defines the starting step for the sampling process, allowing for the continuation or refinement of previously generated samples.
    - Comfy dtype: `INT`
    - Python dtype: `int`
- **`refine_at_step`**
    - Specifies the step at which refinement operations are to be applied, enhancing the detail and quality of the generated images.
    - Comfy dtype: `INT`
    - Python dtype: `int`
- **`preview_method`**
    - Indicates the method used for generating previews of the samples during the sampling process, aiding in the evaluation and adjustment of parameters.
    - Comfy dtype: `COMBO[STRING]`
    - Python dtype: `str`
- **`vae_decode`**
    - A flag indicating whether the VAE decoder should be used to transform the latent representation back into image space, affecting the final output quality.
    - Comfy dtype: `COMBO[STRING]`
    - Python dtype: `bool`
### Optional
- **`optional_vae`**
    - An optional VAE model that can be used in the sampling process for additional image refinement or processing.
    - Comfy dtype: `VAE`
    - Python dtype: `tuple`
- **`script`**
    - An optional script that can be executed as part of the sampling process, allowing for custom operations or modifications.
    - Comfy dtype: `SCRIPT`
    - Python dtype: `str`
## Output types
- **`SDXL_TUPLE`**
    - Comfy dtype: `SDXL_TUPLE`
    - The output tuple specific to Stable Diffusion XL models, encapsulating the model's state after sampling.
    - Python dtype: `tuple`
- **`LATENT`**
    - Comfy dtype: `LATENT`
    - The latent representation of the image generated during the sampling process.
    - Python dtype: `torch.Tensor`
- **`VAE`**
    - Comfy dtype: `VAE`
    - The VAE model used in the sampling process, if applicable.
    - Python dtype: `torch.nn.Module`
- **`IMAGE`**
    - Comfy dtype: `IMAGE`
    - The final image output generated from the sampling process.
    - Python dtype: `torch.Tensor`
## Usage tips
- Infra type: `GPU`
- Common nodes:
    - [SaveImage](../../Comfy/Nodes/SaveImage.md)
    - [PreviewImage](../../Comfy/Nodes/PreviewImage.md)
    - [Image Filter Adjustments](../../was-node-suite-comfyui/Nodes/Image Filter Adjustments.md)
    - [IterativeLatentUpscale](../../ComfyUI-Impact-Pack/Nodes/IterativeLatentUpscale.md)



## Source code
```python
class TSC_KSamplerSDXL(TSC_KSampler):

    @classmethod
    def INPUT_TYPES(cls):
        return {"required":
                    {"sdxl_tuple": ("SDXL_TUPLE",),
                     "noise_seed": ("INT", {"default": 0, "min": 0, "max": 0xffffffffffffffff}),
                     "steps": ("INT", {"default": 20, "min": 1, "max": 10000}),
                     "cfg": ("FLOAT", {"default": 7.0, "min": 0.0, "max": 100.0}),
                     "sampler_name": (comfy.samplers.KSampler.SAMPLERS,),
                     "scheduler": (comfy.samplers.KSampler.SCHEDULERS,),
                     "latent_image": ("LATENT",),
                     "start_at_step": ("INT", {"default": 0, "min": 0, "max": 10000}),
                     "refine_at_step": ("INT", {"default": -1, "min": -1, "max": 10000}),
                     "preview_method": (["auto", "latent2rgb", "taesd", "none"],),
                     "vae_decode": (["true", "true (tiled)", "false", "output only", "output only (tiled)"],),
                     },
                "optional": {"optional_vae": ("VAE",),
                             "script": ("SCRIPT",),},
                "hidden": {"prompt": "PROMPT", "extra_pnginfo": "EXTRA_PNGINFO", "my_unique_id": "UNIQUE_ID",},
                }

    RETURN_TYPES = ("SDXL_TUPLE", "LATENT", "VAE", "IMAGE",)
    RETURN_NAMES = ("SDXL_TUPLE", "LATENT", "VAE", "IMAGE",)
    OUTPUT_NODE = True
    FUNCTION = "sample_sdxl"
    CATEGORY = "Efficiency Nodes/Sampling"

    def sample_sdxl(self, sdxl_tuple, noise_seed, steps, cfg, sampler_name, scheduler, latent_image,
               start_at_step, refine_at_step, preview_method, vae_decode, prompt=None, extra_pnginfo=None,
               my_unique_id=None, optional_vae=(None,), refiner_extras=None, script=None):
        # sdxl_tuple sent through the 'model' channel
        negative = None
        return super().sample(sdxl_tuple, noise_seed, steps, cfg, sampler_name, scheduler,
               refiner_extras, negative, latent_image, preview_method, vae_decode, denoise=1.0,
               prompt=prompt, extra_pnginfo=extra_pnginfo, my_unique_id=my_unique_id, optional_vae=optional_vae,
               script=script, add_noise=None, start_at_step=start_at_step, end_at_step=refine_at_step,
               return_with_leftover_noise=None,sampler_type="sdxl")

```
