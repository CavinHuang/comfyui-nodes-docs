# Documentation
- Class name: CropByMask
- Category: ðŸ˜ºdzNodes/LayerMask
- Output node: False
- Repo Ref: https://github.com/chflame163/ComfyUI_LayerStyle

å°†å›¾ç‰‡æŒ‰ç…§maskèŒƒå›´è£åˆ‡ï¼Œå¯è®¾ç½®å››å‘¨è¾¹æ¡†ä¿ç•™å¤§å°ã€‚è¿™ä¸ªèŠ‚ç‚¹ä¸ŽRestoreCropBoxå’ŒImageScaleRestoreé…åˆä½¿ç”¨ï¼Œå¯ä»¥å¯¹å›¾ç‰‡çš„å±€éƒ¨è¿›è¡Œè£åˆ‡ï¼Œæ”¾å¤§ä¿®æ”¹åŽè´´å›žåŽŸå¤„ã€‚

# Input types
## Required

- image
    - è¾“å…¥å›¾ç‰‡ã€‚
    - Comfy dtype: IMAGE
    - Python dtype: torch.Tensor

- mask_for_crop
    - imageçš„é®ç½©ï¼Œå°†è‡ªåŠ¨æŒ‰ç…§é®ç½©èŒƒå›´è¿›è¡Œè£åˆ‡ã€‚
    - Comfy dtype: MASK
    - Python dtype: torch.Tensor

- invert_mask
    - æ˜¯å¦åè½¬maskã€‚
    - Comfy dtype: BOOLEAN
    - Python dtype: bool

- detect
    - æŽ¢æµ‹æ–¹æ³•ï¼Œmin_bounding_rectæ˜¯å¤§å—å½¢çŠ¶æœ€å°å¤–æŽ¥çŸ©å½¢, max_inscribed_rectæ˜¯å¤§å—å½¢çŠ¶æœ€å¤§å†…æŽ¥çŸ©å½¢, mask_areaæ˜¯é®ç½©åƒç´ æœ‰æ•ˆåŒºåŸŸã€‚
    - Comfy dtype: STRING
    - Python dtype: str

- top_reserve
    - è£åˆ‡é¡¶ç«¯ä¿ç•™å¤§å°ã€‚
    - Comfy dtype: INT
    - Python dtype: int

- bottom_reserve
    - è£åˆ‡åº•ç«¯ä¿ç•™å¤§å°ã€‚
    - Comfy dtype: INT
    - Python dtype: int

- left_reserve
    - è£åˆ‡å·¦ä¾§ä¿ç•™å¤§å°ã€‚
    - Comfy dtype: INT
    - Python dtype: int

- right_reserve
    - è£åˆ‡å³ä¾§ä¿ç•™å¤§å°ã€‚
    - Comfy dtype: INT
    - Python dtype: int

# Output types

- croped_image
    - è£åˆ‡åŽçš„å›¾ç‰‡ã€‚
    - Comfy dtype: IMAGE
    - Python dtype: torch.Tensor

- croped_mask
    - è£åˆ‡åŽçš„maskã€‚
    - Comfy dtype: MASK
    - Python dtype: torch.Tensor

- crop_box
    - è£åˆ‡boxæ•°æ®ï¼Œåœ¨RestoreCropBoxèŠ‚ç‚¹æ¢å¤æ—¶ä½¿ç”¨ã€‚
    - Comfy dtype: BOX
    - Python dtype: list

- box_preview
    - è£åˆ‡ä½ç½®é¢„è§ˆå›¾ï¼Œçº¢è‰²æ˜¯æŽ¢æµ‹åˆ°çš„èŒƒå›´ï¼Œç»¿è‰²æ˜¯åŠ ä¸Šä¿ç•™è¾¹æ¡†åŽè£åˆ‡çš„èŒƒå›´ã€‚
    - Comfy dtype: IMAGE
    - Python dtype: torch.Tensor

# Usage tips
- Infra type: GPU

# Source code
```
class CropByMask:

    def __init__(self):
        pass

    @classmethod
    def INPUT_TYPES(self):
        detect_mode = ['min_bounding_rect', 'max_inscribed_rect', 'mask_area']
        return {
            "required": {
                "image": ("IMAGE", ),  #
                "mask_for_crop": ("MASK",),
                "invert_mask": ("BOOLEAN", {"default": False}),  # åè½¬mask#
                "detect": (detect_mode,),
                "top_reserve": ("INT", {"default": 20, "min": -9999, "max": 9999, "step": 1}),
                "bottom_reserve": ("INT", {"default": 20, "min": -9999, "max": 9999, "step": 1}),
                "left_reserve": ("INT", {"default": 20, "min": -9999, "max": 9999, "step": 1}),
                "right_reserve": ("INT", {"default": 20, "min": -9999, "max": 9999, "step": 1}),
            },
            "optional": {
            }
        }

    RETURN_TYPES = ("IMAGE", "MASK", "BOX", "IMAGE",)
    RETURN_NAMES = ("croped_image", "croped_mask", "crop_box", "box_preview")
    FUNCTION = 'crop_by_mask'
    CATEGORY = 'ðŸ˜ºdzNodes/LayerUtility'

    def crop_by_mask(self, image, mask_for_crop, invert_mask, detect,
                  top_reserve, bottom_reserve, left_reserve, right_reserve
                  ):

        ret_images = []
        ret_masks = []
        l_images = []
        l_masks = []


        for l in image:
            l_images.append(torch.unsqueeze(l, 0))
        if mask_for_crop.dim() == 2:
            mask_for_crop = torch.unsqueeze(mask_for_crop, 0)
        # å¦‚æžœæœ‰å¤šå¼ maskè¾“å…¥ï¼Œä½¿ç”¨ç¬¬ä¸€å¼ 
        if mask_for_crop.shape[0] > 1:
            log(f"Warning: Multiple mask inputs, using the first.", message_type='warning')
            mask_for_crop = torch.unsqueeze(mask_for_crop[0], 0)
        if invert_mask:
            mask_for_crop = 1 - mask_for_crop
        l_masks.append(tensor2pil(torch.unsqueeze(mask_for_crop, 0)).convert('L'))

        _mask = mask2image(mask_for_crop)
        bluredmask = gaussian_blur(_mask, 20).convert('L')
        x = 0
        y = 0
        width = 0
        height = 0
        if detect == "min_bounding_rect":
            (x, y, width, height) = min_bounding_rect(bluredmask)
        elif detect == "max_inscribed_rect":
            (x, y, width, height) = max_inscribed_rect(bluredmask)
        else:
            (x, y, width, height) = mask_area(_mask)

        width = num_round_to_multiple(width, 8)
        height = num_round_to_multiple(height, 8)
        log(f"{NODE_NAME}: Box detected. x={x},y={y},width={width},height={height}")
        canvas_width, canvas_height = tensor2pil(torch.unsqueeze(image[0], 0)).convert('RGB').size
        x1 = x - left_reserve if x - left_reserve > 0 else 0
        y1 = y - top_reserve if y - top_reserve > 0 else 0
        x2 = x + width + right_reserve if x + width + right_reserve < canvas_width else canvas_width
        y2 = y + height + bottom_reserve if y + height + bottom_reserve < canvas_height else canvas_height
        preview_image = tensor2pil(mask_for_crop).convert('RGB')
        preview_image = draw_rect(preview_image, x, y, width, height, line_color="#F00000", line_width=(width+height)//100)
        preview_image = draw_rect(preview_image, x1, y1, x2 - x1, y2 - y1,
                                  line_color="#00F000", line_width=(width+height)//200)
        crop_box = (x1, y1, x2, y2)
        for i in range(len(l_images)):
            _canvas = tensor2pil(l_images[i]).convert('RGB')
            _mask = l_masks[0]
            ret_images.append(pil2tensor(_canvas.crop(crop_box)))
            ret_masks.append(image2mask(_mask.crop(crop_box)))

        log(f"{NODE_NAME} Processed {len(ret_images)} image(s).", message_type='finish')
        return (torch.cat(ret_images, dim=0), torch.cat(ret_masks, dim=0), list(crop_box), pil2tensor(preview_image),)

```