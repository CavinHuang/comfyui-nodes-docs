# Documentation
- Class name: MaskEdgeUltraDetail
- Category: ğŸ˜ºdzNodes/LayerMask
- Output node: False
- Repo Ref: https://github.com/chflame163/ComfyUI_LayerStyle

å¤„ç†è¾ƒç²—ç³™çš„é®ç½©ä½¿å…¶è·å¾—è¶…ç²¾ç»†è¾¹ç¼˜ã€‚ æœ¬èŠ‚ç‚¹ç»“åˆäº†spacepxlçš„[ComfyUI-Image-Filters](https://github.com/spacepxl/ComfyUI-Image-Filters)çš„Alpha Matteå’ŒGuided Filter Alphaä¸¤è€…åŠŸèƒ½ï¼Œæ„Ÿè°¢åŸä½œè€…ã€‚

# Input types

## Required

- image
    - è¾“å…¥çš„å›¾åƒã€‚
    - Comfy dtype: IMAGE
    - Python dtype: torch.Tensor

- mask
    - è¾“å…¥çš„é®ç½©ã€‚
    - Comfy dtype: MASK
    - Python dtype: torch.Tensor

- method
    - æä¾›PyMattingå’ŒOpenCV-GuidedFilterä¸¤ç§æ–¹æ³•å¤„ç†è¾¹ç¼˜ã€‚PyMattingå¤„ç†é€Ÿåº¦è¾ƒæ…¢ï¼Œä½†æ˜¯å¯¹äºè§†é¢‘ï¼Œå»ºè®®ä½¿ç”¨è¿™ç§æ–¹æ³•è·å¾—æ›´å¹³æ»‘çš„é®ç½©åºåˆ—ã€‚
    - Comfy dtype: LIST
    - Python dtype: str

- mask_grow
    - é®ç½©æ‰©å¼ å¹…åº¦ã€‚æ­£å€¼æ˜¯å‘å¤–æ‰©å¼ ï¼Œè´Ÿå€¼æ˜¯å‘å†…æ”¶ç¼©ã€‚å¯¹äºè¾ƒç²—ç³™çš„é®ç½©ï¼Œé€šå¸¸ä½¿ç”¨è´Ÿå€¼ä½¿å…¶è¾¹ç¼˜æ”¶ç¼©ä»¥è·å¾—æ›´å¥½çš„æ•ˆæœã€‚
    - Comfy dtype: INT
    - Python dtype: int

- fix_gap
    - ä¿®è¡¥é®ç½©ä¸­çš„ç©ºéš™ã€‚å¦‚æœé®ç½©ä¸­æœ‰æ¯”è¾ƒæ˜æ˜¾çš„ç©ºéš™ï¼Œé€‚å½“è°ƒé«˜æ­¤æ•°å€¼ã€‚
    - Comfy dtype: INT
    - Python dtype: int

- fix_threshold
    - ä¿®è¡¥é®ç½©çš„é˜ˆå€¼ã€‚
    - Comfy dtype: FLOAT
    - Python dtype: float

- detail_range
    - è¾¹ç¼˜ç»†èŠ‚èŒƒå›´ã€‚
    - Comfy dtype: INT
    - Python dtype: int

- black_point
    - è¾¹ç¼˜é»‘è‰²é‡‡æ ·é˜ˆå€¼ã€‚
    - Comfy dtype: FLOAT
    - Python dtype: float

- white_point
    - è¾¹ç¼˜é»‘è‰²é‡‡æ ·é˜ˆå€¼ã€‚
    - Comfy dtype: FLOAT
    - Python dtype: float

# Output types

- image
    - è¾“å‡ºçš„å›¾åƒã€‚
    - Comfy dtype: IMAGE
    - Python dtype: torch.Tensor

- mask
    - è¾“å‡ºçš„é®ç½©ã€‚
    - Comfy dtype: MASK
    - Python dtype: torch.Tensor

# Usage tips
- Infra type: CPU

# Source code
```python
class MaskEdgeUltraDetail:
    def __init__(self):
        pass

    @classmethod
    def INPUT_TYPES(cls):
        method_list = ['PyMatting', 'OpenCV-GuidedFilter']
        return {
            "required": {
                "image": ("IMAGE",),
                "mask": ("MASK",),
                "method": (method_list,),
                "mask_grow": ("INT", {"default": 0, "min": -999, "max": 999, "step": 1}),
                "fix_gap": ("INT", {"default": 0, "min": 0, "max": 32, "step": 1}),
                "fix_threshold": ("FLOAT", {"default": 0.75, "min": 0.01, "max": 0.99, "step": 0.01}),
                "detail_range": ("INT", {"default": 12, "min": 1, "max": 256, "step": 1}),
                "black_point": ("FLOAT", {"default": 0.01, "min": 0.01, "max": 0.98, "step": 0.01}),
                "white_point": ("FLOAT", {"default": 0.99, "min": 0.02, "max": 0.99, "step": 0.01}),
            },
            "optional": {
            }
        }

    RETURN_TYPES = ("IMAGE", "MASK", )
    RETURN_NAMES = ("image", "mask", )
    FUNCTION = "mask_edge_ultra_detail"
    CATEGORY = 'ğŸ˜ºdzNodes/LayerMask'

    def mask_edge_ultra_detail(self, image, mask, method, mask_grow, fix_gap, fix_threshold,
                               detail_range, black_point, white_point,):
        ret_images = []
        ret_masks = []
        l_images = []
        l_masks = []
        if mask.dim() == 2:
            mask = torch.unsqueeze(mask, 0)
        for l in image:
            l_images.append(torch.unsqueeze(l, 0))
        for m in mask:
            l_masks.append(torch.unsqueeze(m, 0))
        if len(l_images) != len(l_masks) or tensor2pil(l_images[0]).size != tensor2pil(l_masks[0]).size:
            log(f"Error: {NODE_NAME} skipped, because mask does'nt match image.", message_type='error')
            return (image, mask,)

        for i in range(len(l_images)):
            _image = l_images[i]
            orig_image = tensor2pil(_image).convert('RGB')
            _image = pil2tensor(orig_image)
            _mask = l_masks[i]
            if mask_grow != 0:
                _mask = expand_mask(_mask, mask_grow, mask_grow//2)
            if fix_gap:
                _mask = mask_fix(_mask, 1, fix_gap, fix_threshold, fix_threshold)
            if method == 'OpenCV-GuidedFilter':
                _mask = guided_filter_alpha(_image, _mask, detail_range)
                _mask = tensor2pil(histogram_remap(_mask, black_point, white_point))
            else:
                _mask = tensor2pil(mask_edge_detail(_image, _mask, detail_range, black_point, white_point))

            ret_image = RGB2RGBA(orig_image, _mask.convert('L'))
            ret_images.append(pil2tensor(ret_image))
            ret_masks.append(image2mask(_mask))

        log(f"{NODE_NAME} Processed {len(ret_images)} image(s).", message_type='finish')
        return (torch.cat(ret_images, dim=0), torch.cat(ret_masks, dim=0),)
```