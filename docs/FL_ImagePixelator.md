
# Documentation
- Class name: FL_ImagePixelator
- Category: ğŸµï¸Fill Nodes
- Output node: False
- Repo Ref: https://github.com/fillmeout/image_manipulators/FL_ImagePixelator

FL_ImagePixelatorèŠ‚ç‚¹èƒ½å¤Ÿä¸ºå›¾åƒæ·»åŠ åƒç´ åŒ–æ•ˆæœï¼Œæ”¯æŒå•å¼ å›¾åƒå’Œæ‰¹é‡å›¾åƒå¤„ç†ã€‚å®ƒå¯ä»¥å¤„ç†tensoræ ¼å¼æˆ–PILæ ¼å¼çš„å›¾åƒï¼Œé€šè¿‡åº”ç”¨ç¼©æ”¾å› å­æ¥å®ç°å›¾åƒåƒç´ åŒ–ï¼Œå¹¶ä½¿ç”¨æŒ‡å®šçš„æ ¸å¤§å°è¿›è¡Œé¢å¤–å¤„ç†ï¼Œä»è€Œå¢å¼ºåƒç´ åŒ–æ•ˆæœã€‚

# Input types
## Required
- image
    - éœ€è¦è¿›è¡Œåƒç´ åŒ–å¤„ç†çš„å›¾åƒã€‚å¯ä»¥æ˜¯å•å¼ å›¾åƒæˆ–ä¸€æ‰¹å›¾åƒï¼Œæ ¼å¼å¯ä»¥æ˜¯torch.Tensoræˆ–PIL.Imageã€‚è¿™æ˜¯åƒç´ åŒ–å¤„ç†çš„ä¸»è¦è¾“å…¥ã€‚
    - Comfy dtype: IMAGE
    - Python dtype: Union[torch.Tensor, PIL.Image.Image]
- scale_factor
    - å†³å®šåƒç´ åŒ–æ•ˆæœçš„å¼ºåº¦ï¼Œé€šè¿‡åœ¨æ”¾å¤§å‰å…ˆå°†å›¾åƒåˆ†è¾¨ç‡é™ä½æ¥å®ç°ã€‚
    - Comfy dtype: FLOAT
    - Python dtype: float
- kernel_size
    - æŒ‡å®šåƒç´ åŒ–åé¢å¤–å¤„ç†æ­¥éª¤ä¸­ä½¿ç”¨çš„æ ¸å¤§å°ï¼Œå½±å“æœ€ç»ˆåƒç´ åŒ–å›¾åƒçš„å¤–è§‚ã€‚
    - Comfy dtype: INT
    - Python dtype: int

# Output types
- image
    - æ ¹æ®æŒ‡å®šçš„ç¼©æ”¾å› å­å’Œæ ¸å¤§å°å¤„ç†åçš„åƒç´ åŒ–å›¾åƒã€‚å¯ä»¥æ˜¯å•å¼ å›¾åƒæˆ–ä¸€æ‰¹å›¾åƒï¼Œæ ¼å¼ä¸è¾“å…¥ç›¸åŒã€‚
    - Comfy dtype: IMAGE
    - Python dtype: Union[torch.Tensor, PIL.Image.Image]


## Usage tips
- Infra type: `GPU`
- Common nodes: unknown


## Source code
```python
class FL_ImagePixelator:
    @classmethod
    def INPUT_TYPES(cls):
        return {
            "required": {
                "image": ("IMAGE", {}),
                "scale_factor": ("FLOAT", {"default": 0.0500, "min": 0.0100, "max": 0.2000, "step": 0.0100}),
                "kernel_size": ("INT", {"default": 3, "max": 10, "step": 1}),
            }
        }

    RETURN_TYPES = ("IMAGE",)
    FUNCTION = "pixelate_image"
    CATEGORY = "ğŸµï¸Fill Nodes"

    def pixelate_image(self, image, scale_factor, kernel_size):
        if isinstance(image, torch.Tensor):
            if image.dim() == 4:  # Batch dimension is present
                output_images = []
                total_frames = image.shape[0]
                for i, single_image in enumerate(image, start=1):
                    single_image = single_image.unsqueeze(0)  # Add batch dimension
                    single_image = self.apply_pixelation_tensor(single_image, scale_factor)
                    single_image = self.process(single_image, kernel_size)
                    output_images.append(single_image)
                    print(f"Processing frame {i}/{total_frames}")
                image = torch.cat(output_images, dim=0)  # Concatenate processed images along batch dimension
            elif image.dim() == 3:  # No batch dimension, single image
                image = image.unsqueeze(0)  # Add batch dimension
                image = self.apply_pixelation_tensor(image, scale_factor)
                image = self.process(image, kernel_size)
                image = image.squeeze(0)  # Remove batch dimension
                print("Processing single image")
            else:
                return (None,)
        elif isinstance(image, Image.Image):
            image = self.apply_pixelation_pil(image, scale_factor)
            image = self.process(image, kernel_size)
            print("Processing single PIL image")
        else:
            return (None,)

        return (image,)

    def apply_pixelation_pil(self, input_image, scale_factor):
        width, height = input_image.size
        new_size = (int(width * scale_factor), int(height * scale_factor))
        resized_image = input_image.resize(new_size, Image.NEAREST)
        pixelated_image = resized_image.resize((width, height), Image.NEAREST)
        return pixelated_image

    def apply_pixelation_tensor(self, input_image, scale_factor):
        _, num_channels, height, width = input_image.shape
        new_height, new_width = max(1, int(height * scale_factor)), max(1, int(width * scale_factor))
        resized_tensor = torch.nn.functional.interpolate(input_image, size=(new_height, new_width), mode='nearest')
        output_tensor = torch.nn.functional.interpolate(resized_tensor, size=(height, width), mode='nearest')
        return output_tensor

    def process(self, image, kernel_size):
        device = comfy.model_management.get_torch_device()
        kernel = torch.ones(kernel_size, kernel_size, device=device)
        image_k = image.to(device).movedim(-1, 1)
        output = gradient(image_k, kernel)
        img_out = output.to(comfy.model_management.intermediate_device()).movedim(1, -1)
        return img_out

```
