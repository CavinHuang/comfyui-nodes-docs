# Documentation
- Class name: APISR_Lterative_Zho
- Category: ğŸ”APISR
- Output node: False
- Repo Ref: https://github.com/ZHO-ZHO-ZHO/ComfyUI-APISR.git

è¯¥èŠ‚ç‚¹æ—¨åœ¨ä½¿ç”¨æŒ‡å®šæ¨¡å‹å¢å¼ºå›¾åƒåˆ†è¾¨ç‡ï¼Œä¸“æ³¨äºæé«˜è¾“å…¥å›¾åƒçš„æ¸…æ™°åº¦å’Œç»†èŠ‚ã€‚

# Input types
## Required
- pipe
    - â€˜pipeâ€™å‚æ•°è‡³å…³é‡è¦ï¼Œå®ƒä»£è¡¨äº†ç”¨äºå›¾åƒè¶…åˆ†è¾¨ç‡çš„æ¨¡å‹ã€‚å®ƒæ˜¯èŠ‚ç‚¹åŠŸèƒ½çš„æ ¸å¿ƒï¼Œç›´æ¥å½±å“è¾“å‡ºè´¨é‡ã€‚
    - Comfy dtype: APISRMODEL
    - Python dtype: torch.nn.Module
- image
    - â€˜imageâ€™å‚æ•°æ˜¯å¿…ä¸å¯å°‘çš„ï¼Œå®ƒæ˜¯è¶…åˆ†è¾¨ç‡è¿‡ç¨‹çš„è¾“å…¥ã€‚å…¶è´¨é‡å’Œç‰¹æ€§å½±å“åˆ†è¾¨ç‡æå‡çš„æœ‰æ•ˆæ€§ã€‚
    - Comfy dtype: IMAGE
    - Python dtype: torch.Tensor
- dtype
    - â€˜dtypeâ€™å‚æ•°å†³å®šäº†ç”¨äºå¤„ç†çš„æ•°æ®ç±»å‹ï¼Œè¿™ä¼šå½±å“è¶…åˆ†è¾¨ç‡ç®—æ³•çš„æ€§èƒ½å’Œç²¾åº¦ã€‚
    - Comfy dtype: COMBO[float32, float16]
    - Python dtype: str
## Optional
- crop_for_4x
    - â€˜crop_for_4xâ€™å‚æ•°æ˜¯ä¸€ä¸ªå¯é€‰è®¾ç½®ï¼Œç”¨äºè°ƒæ•´è¾“å…¥å›¾åƒä»¥é€‚åº”4å€ç¼©æ”¾è¦æ±‚ï¼Œç¡®ä¿å…¼å®¹æ€§å’Œæœ€ä½³å¤„ç†ã€‚
    - Comfy dtype: BOOLEAN
    - Python dtype: bool

# Output types
- processed_images
    - â€˜processed_imagesâ€™è¾“å‡ºåŒ…å«è¶…åˆ†è¾¨ç‡å›¾åƒï¼Œä»£è¡¨èŠ‚ç‚¹æ“ä½œçš„ä¸»è¦ç»“æœï¼Œç»†èŠ‚å’Œæ¸…æ™°åº¦å¾—åˆ°å¢å¼ºã€‚
    - Comfy dtype: IMAGE
    - Python dtype: List[torch.Tensor]

# Usage tips
- Infra type: GPU

# Source code
```
class APISR_Lterative_Zho:

    def __init__(self):
        pass

    @classmethod
    def INPUT_TYPES(cls):
        return {'required': {'pipe': ('APISRMODEL',), 'image': ('IMAGE',), 'crop_for_4x': ('BOOLEAN', {'default': True}), 'dtype': (['float32', 'float16'],)}}
    RETURN_TYPES = ('IMAGE',)
    FUNCTION = 'sr_image'
    CATEGORY = 'ğŸ”APISR'

    def sr_image(self, pipe, image, crop_for_4x, dtype):
        if dtype == 'float32':
            weight_dtype = torch.float32
        elif dtype == 'float16':
            weight_dtype = torch.float16
        pipe = pipe.to(device=device, dtype=weight_dtype)
        processed_images = []
        for img_tensor in image:
            img_tensor = img_tensor.to(device=device, dtype=weight_dtype).unsqueeze(0).permute(0, 3, 1, 2)
            if crop_for_4x:
                (_, _, h, w) = img_tensor.shape
                if h % 4 != 0:
                    img_tensor = img_tensor[:, :, :4 * (h // 4), :]
                if w % 4 != 0:
                    img_tensor = img_tensor[:, :, :, :4 * (w // 4)]
            with torch.no_grad():
                super_resolved_img = pipe(img_tensor)
            super_resolved_img_nhwc = super_resolved_img.permute(0, 2, 3, 1).squeeze(0).cpu()
            processed_images.append(super_resolved_img_nhwc)
        return (processed_images,)
```