# Documentation
- Class name: VAEEncodeBatched
- Category: Video Helper Suite ğŸ¥ğŸ…¥ğŸ…—ğŸ…¢/batched nodes
- Output node: False
- Repo Ref: https://github.com/Kosinkadink/ComfyUI-VideoHelperSuite.git

VAEEncodeBatchedèŠ‚ç‚¹æ—¨åœ¨ä½¿ç”¨å˜åˆ†è‡ªç¼–ç å™¨ï¼ˆVAEï¼‰é«˜æ•ˆåœ°å°†è§†é¢‘å¸§æ‰¹æ¬¡ç¼–ç ä¸ºæ½œåœ¨ç©ºé—´è¡¨ç¤ºã€‚å®ƒä»¥æŒ‡å®šçš„æ‰¹æ¬¡å¤§å°å¤„ç†å¸§ï¼Œä»¥ä¼˜åŒ–è®¡ç®—èµ„æºå’Œååé‡ï¼Œä½¿å…¶é€‚åˆå¤„ç†å¤§é‡è§†é¢‘æ•°æ®ã€‚

# Input types
## Required
- pixels
    - â€˜pixelsâ€™å‚æ•°æ˜¯VAEEncodeBatchedèŠ‚ç‚¹çš„å…³é”®è¾“å…¥ï¼Œå› ä¸ºå®ƒä»£è¡¨äº†éœ€è¦ç¼–ç çš„åŸå§‹è§†é¢‘å¸§ã€‚å…¶é«˜æ•ˆå¤„ç†å¯¹èŠ‚ç‚¹çš„æ€§èƒ½å’Œç”Ÿæˆçš„æ½œåœ¨ç©ºé—´è¡¨ç¤ºçš„è´¨é‡è‡³å…³é‡è¦ã€‚
    - Comfy dtype: IMAGE
    - Python dtype: torch.Tensor
- vae
    - â€˜vaeâ€™å‚æ•°æŒ‡å®šäº†èŠ‚ç‚¹å°†ç”¨äºç¼–ç è§†é¢‘å¸§çš„å˜åˆ†è‡ªç¼–ç å™¨æ¨¡å‹ã€‚å®ƒå¯¹äºç¡®å®šå¸§ç¼–ç çš„æ½œåœ¨ç©ºé—´çš„ç»“æ„å’Œç‰¹æ€§è‡³å…³é‡è¦ã€‚
    - Comfy dtype: VAE
    - Python dtype: torch.nn.Module
## Optional
- per_batch
    - â€˜per_batchâ€™å‚æ•°å®šä¹‰äº†èŠ‚ç‚¹è¦å¤„ç†çš„æ¯ä¸ªåƒç´ æ‰¹æ¬¡çš„å¤§å°ã€‚å®ƒå¯¹äºç®¡ç†å†…å­˜ä½¿ç”¨å’Œè®¡ç®—æ•ˆç‡å¾ˆé‡è¦ï¼Œå°¤å…¶æ˜¯åœ¨å¤„ç†é«˜åˆ†è¾¨ç‡æˆ–å¤§é‡è§†é¢‘å¸§æ—¶ã€‚
    - Comfy dtype: INT
    - Python dtype: int

# Output types
- samples
    - VAEEncodeBatchedèŠ‚ç‚¹çš„â€˜samplesâ€™è¾“å‡ºåŒ…å«è¾“å…¥è§†é¢‘å¸§çš„ç¼–ç æ½œåœ¨ç©ºé—´è¡¨ç¤ºã€‚è¿™ä¸ªè¾“å‡ºå¾ˆé‡è¦ï¼Œå› ä¸ºå®ƒæ„æˆäº†ä¸‹æ¸¸ä»»åŠ¡ä¸­è¿›ä¸€æ­¥åˆ†ææˆ–å¤„ç†çš„åŸºç¡€ã€‚
    - Comfy dtype: LATENT
    - Python dtype: torch.Tensor

# Usage tips
- Infra type: GPU

# Source code
```
class VAEEncodeBatched:

    @classmethod
    def INPUT_TYPES(s):
        return {'required': {'pixels': ('IMAGE',), 'vae': ('VAE',), 'per_batch': ('INT', {'default': 16, 'min': 1})}}
    CATEGORY = 'Video Helper Suite ğŸ¥ğŸ…¥ğŸ…—ğŸ…¢/batched nodes'
    RETURN_TYPES = ('LATENT',)
    FUNCTION = 'encode'

    def encode(self, vae, pixels, per_batch):
        t = []
        for start_idx in range(0, pixels.shape[0], per_batch):
            try:
                sub_pixels = vae.vae_encode_crop_pixels(pixels[start_idx:start_idx + per_batch])
            except:
                sub_pixels = VAEEncode.vae_encode_crop_pixels(pixels[start_idx:start_idx + per_batch])
            t.append(vae.encode(sub_pixels[:, :, :, :3]))
        return ({'samples': torch.cat(t, dim=0)},)
```