
# Documentation
- Class name: IG Load Image
- Category: ðŸ“ IG Nodes/IO
- Output node: False

IG Load ImageèŠ‚ç‚¹æ—¨åœ¨ä»ŽæŒ‡å®šç›®å½•åŠ è½½å›¾åƒï¼Œæä¾›äº†å›¾åƒé¢„å¤„ç†åŠŸèƒ½ï¼Œå¦‚æ–¹å‘æ ¡æ­£ã€è½¬æ¢ä¸ºç‰¹å®šé¢œè‰²æ¨¡å¼å’Œæ ‡å‡†åŒ–ã€‚å®ƒç®€åŒ–äº†å›¾åƒåŠ è½½å’Œé¢„å¤„ç†çš„å¤æ‚æ€§ï¼Œä½¿å›¾åƒæ•°æ®æ›´å®¹æ˜“é›†æˆåˆ°å·¥ä½œæµç¨‹ä¸­ã€‚

# Input types
## Required
- image_path
    - image_pathå‚æ•°æŒ‡å®šè¦åŠ è½½çš„å›¾åƒçš„è·¯å¾„ã€‚å®ƒåœ¨ç¡®å®šå°†è¦å¤„ç†å“ªä¸ªå›¾åƒæ–‡ä»¶æ–¹é¢èµ·ç€å…³é”®ä½œç”¨ï¼Œå½±å“èŠ‚ç‚¹çš„æ‰§è¡Œå’Œæœ€ç»ˆçš„å›¾åƒæ•°æ®ã€‚
    - Comfy dtype: STRING
    - Python dtype: str

# Output types
- image
    - imageå‚æ•°ä»£è¡¨ç»è¿‡é¢„å¤„ç†çš„å›¾åƒæ•°æ®ï¼Œå¯ç”¨äºŽè¿›ä¸€æ­¥å¤„ç†æˆ–åˆ†æžã€‚
    - Comfy dtype: IMAGE
    - Python dtype: torch.Tensor
- mask
    - maskå‚æ•°ä¸ºåŠ è½½çš„å›¾åƒæä¾›äº†ä¸€ä¸ªæŽ©ç ï¼Œå¯¹äºŽéœ€è¦åˆ†å‰²æˆ–ç‰¹å®šåŒºåŸŸå¤„ç†çš„æ“ä½œå¾ˆæœ‰ç”¨ã€‚
    - Comfy dtype: MASK
    - Python dtype: torch.Tensor


## Usage tips
- Infra type: `CPU`
- Common nodes: unknown


## Source code
```python
class IG_LoadImage:
    @classmethod
    def INPUT_TYPES(s):
        return {
            "required": {
                "image_path": ("STRING", {"forceInput": True}),
            },
        }
    
    RETURN_TYPES = ("IMAGE", "MASK")
    FUNCTION = "main"

    CATEGORY = TREE_IO

    def main(self, image_path: str, **kwargs):
        img = Image.open(image_path)
        output_images = []
        output_masks = []
        for i in ImageSequence.Iterator(img):
            i = ImageOps.exif_transpose(i)
            if i.mode == 'I':
                i = i.point(lambda i: i * (1 / 255))
            image = i.convert("RGB")
            image = np.array(image).astype(np.float32) / 255.0
            image = torch.from_numpy(image)[None,]
            if 'A' in i.getbands():
                mask = np.array(i.getchannel('A')).astype(np.float32) / 255.0
                mask = 1. - torch.from_numpy(mask)
            else:
                mask = torch.zeros((64,64), dtype=torch.float32, device="cpu")
            output_images.append(image)
            output_masks.append(mask.unsqueeze(0))

        if len(output_images) > 1:
            output_image = torch.cat(output_images, dim=0)
            output_mask = torch.cat(output_masks, dim=0)
        else:
            output_image = output_images[0]
            output_mask = output_masks[0]

        return (output_image, output_mask)
    
    @classmethod
    def IS_CHANGED(s, image_path: str, **kwargs):
        return is_changed_image(image_path, **kwargs)

```
