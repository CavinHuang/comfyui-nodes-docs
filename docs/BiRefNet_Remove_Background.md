# Documentation  
- Class name: BiRefNet_Remove_Background  
- Category: BiRefNetğŸŒŸ  
- Output node: False 
- Repo Ref: https://github.com/moon7star9/ComfyUI_BiRefNet_Universal

BiRefNet_Remove_BackgroundèŠ‚ç‚¹æ˜¯ä¸€ä¸ªç”¨äºå›¾åƒèƒŒæ™¯ç§»é™¤çš„å¤„ç†èŠ‚ç‚¹ã€‚å®ƒæ¥æ”¶å·²åŠ è½½çš„BiRefNetæ¨¡å‹å’Œè¾“å…¥å›¾åƒï¼Œé€šè¿‡æ·±åº¦å­¦ä¹ æ–¹æ³•å‡†ç¡®åˆ†å‰²å‰æ™¯å’ŒèƒŒæ™¯ï¼Œå¹¶å¯ä»¥é€‰æ‹©æ€§åœ°å¯¹å‰æ™¯è¿›è¡Œä¼˜åŒ–å¤„ç†ã€‚èŠ‚ç‚¹æ”¯æŒå¤šç§èƒŒæ™¯å¤„ç†é€‰é¡¹ï¼ŒåŒ…æ‹¬é€æ˜èƒŒæ™¯å’Œå„ç§çº¯è‰²èƒŒæ™¯ï¼ŒåŒæ—¶æä¾›å‰æ™¯ä¼˜åŒ–åŠŸèƒ½ä»¥æé«˜è¾¹ç¼˜è´¨é‡ã€‚  

# Input types  
## Required  
- model  
    - 'model'å‚æ•°æ¥æ”¶ä»BiRefNet_LoaderèŠ‚ç‚¹è¾“å‡ºçš„æ¨¡å‹å®ä¾‹ï¼ŒåŒ…å«äº†é¢„è®­ç»ƒæ¨¡å‹åŠå…¶é…ç½®ä¿¡æ¯ã€‚  
    - Comfy dtype: BIREFNET_MODEL  
    - Python dtype: dict  
- image  
    - 'image'å‚æ•°æ˜¯éœ€è¦å¤„ç†çš„è¾“å…¥å›¾åƒã€‚èŠ‚ç‚¹ä¼šè‡ªåŠ¨è°ƒæ•´å›¾åƒå¤§å°ä»¥åŒ¹é…æ¨¡å‹çš„æœ€ä½³å·¥ä½œåˆ†è¾¨ç‡ã€‚  
    - Comfy dtype: IMAGE  
    - Python dtype: torch.Tensor  
- background_color  
    - 'background_color'å‚æ•°å…è®¸ç”¨æˆ·é€‰æ‹©è¾“å‡ºå›¾åƒçš„èƒŒæ™¯ç±»å‹ï¼Œå¯ä»¥æ˜¯é€æ˜èƒŒæ™¯æˆ–æŒ‡å®šçš„çº¯è‰²èƒŒæ™¯ï¼ˆç™½è‰²ã€é»‘è‰²ã€ç»¿è‰²ã€è“è‰²ã€çº¢è‰²ï¼‰ã€‚  
    - Comfy dtype: COMBO  
    - Python dtype: str  
- use_refine  
    - 'use_refine'å‚æ•°æ§åˆ¶æ˜¯å¦ä½¿ç”¨å‰æ™¯ä¼˜åŒ–åŠŸèƒ½ã€‚å¯ç”¨æ­¤é€‰é¡¹å¯ä»¥æ”¹å–„è¾¹ç¼˜è´¨é‡ï¼Œä½†å¯èƒ½ä¼šç•¥å¾®å¢åŠ å¤„ç†æ—¶é—´ã€‚  
    - Comfy dtype: BOOLEAN  
    - Python dtype: bool  

# Output types  
- IMAGE  
    - è¾“å‡ºå¤„ç†åçš„å›¾åƒï¼Œæ ¹æ®é€‰æ‹©çš„èƒŒæ™¯ç±»å‹å¯èƒ½æ˜¯RGBAï¼ˆé€æ˜èƒŒæ™¯ï¼‰æˆ–RGBï¼ˆçº¯è‰²èƒŒæ™¯ï¼‰æ ¼å¼ã€‚  
    - Comfy dtype: IMAGE  
    - Python dtype: torch.Tensor  
- MASK  
    - è¾“å‡ºåˆ†å‰²æ©ç ï¼Œè¡¨ç¤ºå‰æ™¯åŒºåŸŸçš„äºŒå€¼å›¾åƒã€‚è¿™ä¸ªæ©ç å¯ä»¥ç”¨äºå…¶ä»–èŠ‚ç‚¹çš„è¿›ä¸€æ­¥å¤„ç†ã€‚  
    - Comfy dtype: MASK  
    - Python dtype: torch.Tensor  

# Usage tips  
- Infra type: GPU/CPU  
- æ¨èåœ¨GPUä¸Šè¿è¡Œä»¥è·å¾—æ›´å¥½çš„æ€§èƒ½  
- ä½¿ç”¨é€æ˜èƒŒæ™¯é€‰é¡¹æ—¶ï¼Œè¾“å‡ºå°†æ˜¯RGBAæ ¼å¼  
- å¯ç”¨å‰æ™¯ä¼˜åŒ–å¯ä»¥æ”¹å–„è¾¹ç¼˜è´¨é‡ï¼Œç‰¹åˆ«æ˜¯å¯¹äºå¤æ‚çš„è¾¹ç¼˜ç»†èŠ‚  
- è¾“å‡ºçš„æ©ç å¯ä»¥ç”¨äºå…¶ä»–å›¾åƒå¤„ç†èŠ‚ç‚¹çš„é®ç½©è¾“å…¥  

# Source code  
```python  
class BiRefNet_Remove_Background:  
    @classmethod  
    def INPUT_TYPES(cls):  
        return {  
            "required": {  
                "model": ("BIREFNET_MODEL",),  
                "image": ("IMAGE",),  
                "background_color": (["transparency"] + ["white", "black", "green", "blue", "red"], {"default": "transparency"}),
                "use_refine": ("BOOLEAN", {"default": True})  
            }  
        }  

    RETURN_TYPES = ("IMAGE", "MASK")  
    RETURN_NAMES = ("image", "mask")  
    FUNCTION = "inference"  
    CATEGORY = "BiRefNetğŸŒŸ"  

    def inference(self, image, model, background_color, use_refine):  
        model_data = model  
        model = model_data["model"]  
        device = model_data["device"]  
        use_half_precision = model_data["half_precision"]  
        resolution = model_data["resolution"]  # ç›´æ¥ä½¿ç”¨æ¨¡å‹çš„æœ€ä½³åˆ†è¾¨ç‡  

        preprocessor = ImagePreprocessor(resolution)  
        processed_images = []  
        processed_masks = []  

        for img in image:  
            # è½¬æ¢ä¸ºPILå›¾åƒ  
            orig_image = Image.fromarray(np.clip(255. * img.cpu().numpy().squeeze(), 0, 255).astype(np.uint8))  
            w, h = orig_image.size  
            
            # é¢„å¤„ç†  
            image_tensor = preprocessor(orig_image.convert('RGB')).unsqueeze(0)  
            if use_half_precision:  
                image_tensor = image_tensor.half()  
            image_tensor = image_tensor.to(device)  

            # æ¨ç†  
            with torch.no_grad():  
                preds = model(image_tensor)[-1].sigmoid().cpu()  

            pred = preds[0].squeeze()
            pred_pil = transforms.ToPILImage()(pred)
            mask = pred_pil.resize((w, h))
            

            # é€‰æ‹©åº”ç”¨å‰æ™¯ä¼˜åŒ–  
            if use_refine:  
                refined_image = refine_foreground(orig_image, pred_pil, r=90)  # ä½¿ç”¨å›ºå®šçš„rå€¼å³å¯ï¼ˆå®éªŒéªŒè¯è¿‡è°ƒæ•´rå€¼å¯¹ç»“æœå½±å“å¾ˆå°ï¼‰ 

            # è®¾ç½®èƒŒæ™¯å’Œå‰æ™¯  

            if background_color == "transparency":  
                result_image = Image.new("RGBA", (w, h), (0, 0, 0, 0))  
                result_image.paste(refined_image if use_refine else orig_image, mask=mask)
            else:  
                result_image = Image.new("RGB", (w, h), background_color)  
                result_image.paste(refined_image if use_refine else orig_image, mask=mask)
            
            # è½¬æ¢å›tensor  
            processed_images.append(torch.from_numpy(np.array(result_image).astype(np.float32) / 255.0).unsqueeze(0)) 
            processed_masks.append(torch.from_numpy(np.array(mask).astype(np.float32) / 255.0).unsqueeze(0))  

        return torch.cat(processed_images, dim=0), torch.cat(processed_masks, dim=0)  